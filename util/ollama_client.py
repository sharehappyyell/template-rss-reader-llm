import asyncio
import json
from ollama import AsyncClient
from config import OLLAMA_MODEL_NAME, OLLAMA_TIMEOUT_SECONDS


async def generate_answer(text: str):
    print("ğŸ¤– Ollamaã§è¦ç´„ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
    try:
        client = AsyncClient()

        # asyncio.wait_for ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ç®¡ç†
        response = await asyncio.wait_for(
            client.chat(
                model=OLLAMA_MODEL_NAME,
                messages=[{'role': 'user', 'content': text}],
                think="high"
            ),
            timeout=OLLAMA_TIMEOUT_SECONDS
        )

        return json.loads(response['message']['content'])

    except asyncio.TimeoutError:
        print("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
        return None
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None
